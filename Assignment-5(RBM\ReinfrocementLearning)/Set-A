Assignment 5
Set A)
1) Generate an image by using Restricted Boltzmann Machine using a real image dataset(Use MNIST dataset). Use the DataLoader class of the torch.utils.data library to load training and testing datasets, set the batch size to 64 and apply the transformations. Visualize the real and generated image.
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt


batch_size = 64
num_epochs = 10
learning_rate = 0.001
num_visible = 784
num_hidden = 500


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load MNIST dataset
transform = transforms.Compose([transforms.ToTensor()])
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)


train_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# Define RBM model
class RBM(nn.Module):
    def __init__(self, num_visible, num_hidden):
        super(RBM, self).__init__()
        self.W = nn.Parameter(torch.randn(num_visible, num_hidden) * 0.1)
        self.v_bias = nn.Parameter(torch.zeros(num_visible))
        self.h_bias = nn.Parameter(torch.zeros(num_hidden))

    def sample_h(self, x):
        wx_b = torch.matmul(x, self.W) + self.h_bias
        p_h = torch.sigmoid(wx_b)
        return p_h, torch.bernoulli(p_h)

    def sample_v(self, h):
        wh_b = torch.matmul(h, self.W.t()) + self.v_bias
        p_v = torch.sigmoid(wh_b)
        return p_v, torch.bernoulli(p_v)

    def free_energy(self, x):
        wx_b = torch.matmul(x, self.W) + self.h_bias
        hidden_term = torch.sum(torch.log(1 + torch.exp(wx_b)))
        return -torch.sum(x * self.v_bias) - hidden_term


rbm = RBM(num_visible, num_hidden).to(device)
optimizer = optim.SGD(rbm.parameters(), lr=learning_rate)

# Training
for epoch in range(num_epochs):
    for i, (x, _) in enumerate(train_loader):
        x = x.view(-1, num_visible).to(device)

        x_recon = x
        for _ in range(10):
            _, h_sample = rbm.sample_h(x_recon)
            _, x_recon = rbm.sample_v(h_sample)
        loss = rbm.free_energy(x) - rbm.free_energy(x_recon)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if i % 100 == 0:
            print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {loss.item()}')


with torch.no_grad():
    test_images = next(iter(test_loader))[0].view(-1, num_visible).to(device)
    _, generated_images = rbm.sample_v(torch.bernoulli(torch.sigmoid(torch.matmul(test_images, rbm.W) + rbm.h_bias)))


plt.figure(figsize=(10, 5))
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_images[i].reshape(28, 28), cmap='gray')
    plt.axis('off')
    plt.subplot(2, 10, i+11)
    plt.imshow(generated_images[i].reshape(28, 28), cmap='gray')
    plt.axis('off')
plt.show()












3) Implement Deep Belif network using Restricted RBM to create an effective stack of models to perform digit classification
import pandas as pd
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import BernoulliRBM
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression

# Fetch the MNIST dataset
mnist = fetch_openml('mnist_784', version=1)
X, y = mnist.data, mnist.target

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize the RBM model
rbm = BernoulliRBM(n_components=256, learning_rate=0.01, n_iter=20, verbose=1)

# Initialize the logistic regression model
logistic = LogisticRegression(max_iter=1000)

# Create a pipeline with RBM and Logistic Regression
dbn_pipeline = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])

# Fit the pipeline to the training data
dbn_pipeline.fit(X_train_scaled, y_train)

# Evaluate the pipeline on the test data
dbn_score = dbn_pipeline.score(X_test_scaled, y_test)
print(f'DB Classification score (dbn_score): {dbn_score:.4f}')



